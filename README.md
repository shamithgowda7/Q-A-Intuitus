# Intuitas AI - Intelligent Document Assistant

A production-ready AI-powered document analysis and Q&A system built with Streamlit, LangChain, and Google Gemini. Features multiple modes for different use cases including general chat, study assistance, research analysis, and journaling.

## Project Structure

```
rag-doc-assistant/
â”œâ”€â”€ .env                     # Environment variables (API keys)
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ app.py                  # Streamlit frontend entry point
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ rag_pipeline.py     # Core RAG pipeline logic
â”‚   â”œâ”€â”€ document_loader.py  # Document processing utilities
â”‚   â”œâ”€â”€ vectorstore_handler.py # Vector store operations
â”‚   â””â”€â”€ utils.py            # Utility functions
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ uploads/            # Uploaded documents
â”‚   â””â”€â”€ processed/          # Processed vector stores
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ components.py       # UI components
â””â”€â”€ tests/
    â””â”€â”€ test_pipeline.py    # Basic tests
```

## Setup Instructions

1. **Install dependencies:**

   ```bash
   pip install -r requirements.txt
   ```

2. **Configure API keys:**

   - Edit `.env` file
   - Add your OpenAI API key: `OPENAI_API_KEY="your-actual-key"`
   - Optionally add Gemini key: `GEMINI_API_KEY="your-gemini-key"`

3. **Run the application:**
   ```bash
   streamlit run app.py
   ```

## Usage

1. Upload a PDF, HTML, or Markdown document
2. The system will extract text and show a preview
3. Click "Build vectorstore from this document" to process it
4. Ask questions about the document content
5. Get AI-powered answers with source citations

## Features

- **Document Processing**: Supports PDF, HTML, and Markdown files
- **Text Chunking**: Intelligent text splitting for better retrieval
- **Vector Search**: FAISS-based similarity search
- **Source Citation**: Shows relevant document chunks used for answers
- **Streamlit UI**: Clean, interactive web interface

## Next Steps

- Swap to Gemini embeddings/LLM for different AI provider
- Add highlighting and follow-up chat memory
- Implement multi-file handling
- Add persistence with Chroma/Qdrant for production use

## Testing

Run the basic test:

```bash
pytest tests/test_pipeline.py
```

---

**Ready to hack! ðŸš€**
